{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Con la clase creada en el módulo 7, tener en cuenta diferentes casos en que el código pudiera arrojar error. Por ejemplo, en la creación del objeto recibimos una lista de números enteros pero ¿qué pasa si se envía otro tipo de dato?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(r'/home/gero/Escritorio/Python-Prep/07 - Classes & OOP/ejercicios.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ejercicios as a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Se ha creado una lista vacía. Se esperaba una lista de núemeros enteros",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/gero/Escritorio/Python-Prep/08 - Error Handling/resoluciones.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gero/Escritorio/Python-Prep/08%20-%20Error%20Handling/resoluciones.ipynb#ch0000004?line=0'>1</a>\u001b[0m a1 \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39;49mfunciones(\u001b[39m'\u001b[39;49m\u001b[39mhola\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Escritorio/Python-Prep/08 - Error Handling/ejercicios.py:8\u001b[0m, in \u001b[0;36mfunciones.__init__\u001b[0;34m(self, lista_numeros)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mtype\u001b[39m(lista_numeros) \u001b[39m!=\u001b[39m \u001b[39mlist\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlista \u001b[39m=\u001b[39m []\n\u001b[0;32m----> 8\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mSe ha creado una lista vacía. Se esperaba una lista de núemeros enteros\u001b[39m\u001b[39m'\u001b[39m)  \n\u001b[1;32m      9\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlista \u001b[39m=\u001b[39m lista_numeros\n",
      "\u001b[0;31mValueError\u001b[0m: Se ha creado una lista vacía. Se esperaba una lista de núemeros enteros"
     ]
    }
   ],
   "source": [
    "a1 = a.funciones('hola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = a.funciones([1,2,5,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) En la función que hace la conversión de grados, validar que los parámetros enviados sean los esperados, de no serlo, informar cuáles son los valores esperados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ejercicios' from '/home/gero/Escritorio/Python-Prep/08 - Error Handling/ejercicios.py'>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ejercicios\n",
    "import importlib\n",
    "importlib.reload(ejercicios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ejercicios' from '/home/gero/Escritorio/Python-Prep/08 - Error Handling/ejercicios.py'>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = a.funciones([1,2,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porfavor ingrese nuevamente su origen.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.otras_conversiones(12,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Importar el modulo \"unittest\" y crear los siguientes casos de pruebas sobre la clase utilizada en el punto 2<br>\n",
    "Creacion del objeto incorrecta<br>\n",
    "Creacion correcta del objeto<br>\n",
    "Metodo valor_modal()<br>\n",
    "\n",
    "Se puede usar \"raise ValueError()\" en la creación de la clase para verificar el error. Investigar sobre esta funcionalidad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiPrueba(unittest.TestCase):\n",
    "   \n",
    "    def test_crear_objeto1(self):\n",
    "        param = 'hola'\n",
    "        self.assertRaises(ValueError, a.funciones, param)\n",
    "        #self.failUnlessRaises(ValueError, h.Herramientas, param)\n",
    "\n",
    "    def test_crear_objeto2(self):\n",
    "        param = [1,2,2,5]\n",
    "        a1 = a.funciones(param)\n",
    "        self.assertEqual(a1.lista, param)\n",
    "\n",
    "    \n",
    "    #def metodo_valor_modal (self):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.MiPrueba) ... ok\n",
      "test_crear_objeto2 (__main__.MiPrueba) ... ok\n",
      "test_crear_objeto1 (__main__.ProbandoMiClase) ... ok\n",
      "test_crear_objeto2 (__main__.ProbandoMiClase) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.004s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7fc0bc219880>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Probar una creación incorrecta y visualizar la salida del \"raise\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Se ha creado una lista vacía. Se esperaba una lista de núemeros enteros",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/gero/Escritorio/Python-Prep/08 - Error Handling/resoluciones.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gero/Escritorio/Python-Prep/08%20-%20Error%20Handling/resoluciones.ipynb#ch0000021?line=0'>1</a>\u001b[0m a1 \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39;49mfunciones(\u001b[39m'\u001b[39;49m\u001b[39malgo\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Escritorio/Python-Prep/08 - Error Handling/ejercicios.py:8\u001b[0m, in \u001b[0;36mfunciones.__init__\u001b[0;34m(self, lista_numeros)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mtype\u001b[39m(lista_numeros) \u001b[39m!=\u001b[39m \u001b[39mlist\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlista \u001b[39m=\u001b[39m []\n\u001b[0;32m----> 8\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mSe ha creado una lista vacía. Se esperaba una lista de núemeros enteros\u001b[39m\u001b[39m'\u001b[39m)  \n\u001b[1;32m      9\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlista \u001b[39m=\u001b[39m lista_numeros\n",
      "\u001b[0;31mValueError\u001b[0m: Se ha creado una lista vacía. Se esperaba una lista de núemeros enteros"
     ]
    }
   ],
   "source": [
    "a1 = a.funciones('algo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Agregar casos de pruebas para el método verifica_primos() realizando el cambio en la clase, para que devuelva una lista de True o False en función de que el elemento en la posisicón sea o no primo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegundaPrueba(unittest.TestCase):\n",
    "\n",
    "    def verificar_primos(self):\n",
    "        lista = [4,5,7,8]\n",
    "        a1 = a.funciones(lista)\n",
    "        primos = a1.es_primo()\n",
    "        lista_correcta = [False,True,True,False]\n",
    "        self.assertEqual(primos,lista_correcta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ejercicios' from '/home/gero/Escritorio/Python-Prep/08 - Error Handling/ejercicios.py'>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.MiPrueba) ... ok\n",
      "test_crear_objeto2 (__main__.MiPrueba) ... ok\n",
      "test_crear_objeto1 (__main__.ProbandoMiClase) ... ok\n",
      "test_crear_objeto2 (__main__.ProbandoMiClase) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.005s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7fc0bc1214f0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2 , exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Agregar casos de pruebas para el método conversion_grados()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tercera_Prueba (unittest.TestCase):\n",
    "\n",
    "    def conversiones (self):\n",
    "        lista = [80,45,20,3]\n",
    "        a1 = a.funciones(lista)\n",
    "        convertidos = a1.conversiones('Celsius','Farenheit')\n",
    "        conversiones_correctas = [176.0,113.0,68.0,37.4]\n",
    "        self.assertEqual(convertidos,conversiones_correctas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ejercicios' from '/home/gero/Escritorio/Python-Prep/08 - Error Handling/ejercicios.py'>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.MiPrueba) ... ok\n",
      "test_crear_objeto2 (__main__.MiPrueba) ... ok\n",
      "test_crear_objeto1 (__main__.ProbandoMiClase) ... ok\n",
      "test_crear_objeto2 (__main__.ProbandoMiClase) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.004s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7fc0bc177310>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Agregar casos de pruebas para el método factorial()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cuarta_Prueba(unittest.TestCase):\n",
    "    \n",
    "    def prueba_factorial(self):\n",
    "        lista = [2,4,5]\n",
    "        a1 = a.funciones(lista)\n",
    "        factoriales = a1.factorial__()\n",
    "        fact_correctos = [2,24,120]\n",
    "        self.assertEqual(factoriales,fact_correctos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ejercicios' from '/home/gero/Escritorio/Python-Prep/08 - Error Handling/ejercicios.py'>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.MiPrueba) ... ok\n",
      "test_crear_objeto2 (__main__.MiPrueba) ... ok\n",
      "test_crear_objeto1 (__main__.ProbandoMiClase) ... ok\n",
      "test_crear_objeto2 (__main__.ProbandoMiClase) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7fc0bc12c910>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Completar el código en las funciones del archivo \"checkpoint.py\" y probarlo a partir de la ejecución del script \"tests.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClaseAnimal(especie, color):\n",
    "    \n",
    "    class Animal:\n",
    "        def __init__ (self,especie,color):\n",
    "            self.edad = 0\n",
    "            self.especie = especie\n",
    "            self.color = color\n",
    "\n",
    "\n",
    "        def CumplirAnios(self):\n",
    "            self.edad += 1\n",
    "            return self.edad\n",
    "    \n",
    "    m = Animal(especie,color)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ClaseAnimal('Tigre','Naranja')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.CumplirAnios()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
